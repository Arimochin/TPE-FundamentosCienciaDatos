{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _TP especial Fundamentos de la Ciencia de Datos_<br>\n",
    "### _Grupo 7: Buralli, Todesco, Antúnez_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Descarga y lectura de archivos<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos descargando y leyendo los archivos mandados por la cátedra"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Librerias que utilizaremos más tarde\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# importamos wget y las librerías que nos faltan para la descarga\n",
    "from wget import download\n",
    "from os import path\n",
    "\n",
    "# Descargamos el archivo de las canciones\n",
    "if not path.exists(\"Covers.csv\"):\n",
    "  download(\"https://raw.githubusercontent.com/Arimochin/TPE-FundamentosCienciaDatos/main/Covers.csv\")\n",
    "else:\n",
    "  print(\"No se descargará el archivo de las canciones porque ya existe en la carpeta\")\n",
    "# abrimos el archivo usando una función específica de pandas\n",
    "covers_dataset = pd.read_csv(\"Covers.csv\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una vista general para saber de que se trata el dataset, que significan cada una de sus columnas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Descripción de las variables<u>\n",
    "* ```Track```: nombre de la canción\n",
    "* ```Artist```: nombre del artista o intérprete\n",
    "* ```Duration```: duración en minutos de la canción\n",
    "* ```Time_Signature```: número de pulsaciones por compás\n",
    "* ```Danceability```: medida de que tan bailable es la canción(entre 0 y 1)\n",
    "* ```Energy```: medida de que tan enérgica es la canción(entre 0 y 1)\n",
    "* ```Key```: tonalidad de la canción, número entero\n",
    "* ```Loudness```: volumen de la canción, en decibelios\n",
    "* ```Mode```: tono mayor o menor(0 o 1, respectivamente)\n",
    "* ```Speechiness```: medida de presencia de palabras habladas en las canciones, valores altos indican una alta presencia de estas palabras\n",
    "* ```Acoustiness```: mide que tan acústica es la pista\n",
    "* ```Instrumentalness```: mide la presencia de voces en las canciones, valores más altos indican una canción con mayor parte instrumental\n",
    "* ```Liveness```: probabilidad de que dicha canción se haya interpretado en vivo, niveles más altos indican mayor presencia de voces de la audiencia\n",
    "* ```Valance```: medida de la positividad de la canción, niveles más altos indican presencias de melodías alegres\n",
    "* ```Tempo```: velocidad de la pista, medida en beats por minutos(BPM)\n",
    "* ```Popularity```: puntuación de la canción que mide su popularidad\n",
    "* ```Year```: año de lanzamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificaremos la cantidad de nulos mediante el comando ```isna()```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset.isna().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que no hay NaNs, pero esto no descarta la presencia de valores extraños a analizar en las distintas columnas, por lo que verificaremos mediante el método ```value_count()```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Revision de valores<u>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset[\"Track\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ```Track``` parece no haber presencia de valores raros, si algunos nombres repetidos."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset[\"Artist\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con ```Artist``` parace algo similar, nada extraño a primera vista"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset[\"Duration\"].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Duration``` tampoco parece tener valores atípicos, aunque luego habría que convertir el dato a algo numérico."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Time_Signature'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Time_Signature``` parece correcto."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Danceability'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ```Danceability``` no parece que haya nada raro."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Energy'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primera vista no parece haber valores extraño."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Key'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo parece normal en ```Key```."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Loudness'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sospechosos los valores que se repiten 3 veces siendo una variable continua pero aceptable..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Mode'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predominancia del valor de 1 en ```Mode```."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Speechiness'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores repetidos en una variable continua. Candidatos a invertigacion: 0.0352,0.0321,0.0270    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Acousticness'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay valores repetidos 5 veces, puede investigarse..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Instrumentalness'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos registros con 0 de ```Instrumentalness```, asumimos que 0 significa que la cancion es \"Acapella\" valores altos de ```instrumentalness``` como bien describimos al principio corresponden o \"deberian\" corresponder a canciones con mayor presencia instrumental. Mientras que valores menores indican lo contrario. Resaltamos el ```deberia``` porque investigando algunas canciones con valores ```instrumentalness``` estas si poseen instrumentacion."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Instrumentalness'].max()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Liveness'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primera vista no sabemos bien la razon pero en ```Liveness``` hay valores repetidos en 0.1xxx osea todos los valores que son 0.1 y algo mas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Valence'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos valores repetidos en ```Valence``` pero zafa..."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Tempo'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aceptable, quizas los valores 118.777 y 100.002 podrian revisarse, tampoco que se repitan tanto en ```Tempo```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Popularity'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable discreta asi que esta bien que se repitan cosas. Tampoco exageremos!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset['Year'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que todas las canciones son de los '90, pero nada extraño que destacar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Corrección de tipos<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ahora nos ocuparemos de comprobar que los tipos de las variables sean adecuados a lo que representan. Para ello, usamos el método ```info()```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "covers_dataset.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos una copia mediante el método ```copy()``` para no arruinar el dataset original"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds = covers_dataset.copy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos centraremos en arreglar el tipo de la variable ```Duration```, convirtiendolo de string a integer(segundos)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Por las dudas hacemos un cambio de tipos a string.\n",
    "copy_covers_ds['Duration'] = copy_covers_ds['Duration'].astype(str)\n",
    "#Creamos la nueva columna con los valores correctos convertidos a segundos(todavia no estan los valores).\n",
    "copy_covers_ds['DURATION(s)'] = 0\n",
    "#Por cada registro hacemos:\n",
    "for index,row in copy_covers_ds.iterrows():\n",
    "    #duracion original se vuelve el valor de duracion de la fila.\n",
    "    duracion_original = row['Duration']\n",
    "    #Separamos por : los minutos y segundos.\n",
    "    minutos , segundos = duracion_original.split(':')\n",
    "    #Asignamos los minutos * 60 + los segundos obtenidos a la fila en la columna nueva, casteamos ambos parametros a segundos porque sino hace cualquier cosa.\n",
    "    copy_covers_ds.at[index,'DURATION(s)'] = int(minutos) * 60 + int(segundos)\n",
    "#Mostramos resultados.\n",
    "copy_covers_ds.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Analisis de distribuciones<u>\n",
    "\n",
    "\n",
    "Ahora observaremos como se distribuye cada variable para poder aprender un poco sobre el conjunto de datos y obtener conclusiones. Tomaremos las variables más interesantes para analizar y cuyo gráfico nos pueda aportar algo de valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Valence```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ordenamos los datos\n",
    "valence_sort = copy_covers_ds['Valence'].sort_values()\n",
    "\n",
    "# Definimos el número de intervalos (bins)\n",
    "bins = 20\n",
    "\n",
    "# Graficamos el histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(valence_sort, bins=bins)\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Histograma de Valence')\n",
    "plt.xlabel('Valence')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.xticks(np.arange(0,1,0.1))\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva se ve bastante balanceada, hay un pico justo en el centro de la distribucion lo que indica una gran cantidad de canciones con una valenic apromedio."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mas_valencia =  copy_covers_ds[covers_dataset['Valence'] > 0.95].sort_values('Valence')\n",
    "mas_valencia"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "menos_valencia =  copy_covers_ds[covers_dataset['Valence'] < 0.05].sort_values('Valence')\n",
    "menos_valencia"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Popularity```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ordenamos los datos\n",
    "popularity_sort = copy_covers_ds['Popularity'].sort_values()\n",
    "\n",
    "# Definimos el número de intervalos (bins)\n",
    "bins = 20\n",
    "\n",
    "# Graficamos el histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(popularity_sort, bins=bins)\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Histograma de Popularity')\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.xticks(np.arange(0,100,5))\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver una curva bastante sesgada hacia la izquierda. Analicemos las canciones con mas popularidad!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mas_populares =  copy_covers_ds[covers_dataset['Popularity'] > 85].sort_values('Popularity')\n",
    "mas_populares"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora las menos populares!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "menos_populares =  copy_covers_ds[covers_dataset['Popularity'] < 15].sort_values('Popularity')\n",
    "menos_populares"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Nos quedamos solo con la columna Danceability\n",
    "popularity = covers_dataset[\"Popularity\"]\n",
    "\n",
    "# Creamos el boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=popularity)\n",
    "plt.title(\"Boxplot de Popularity\")\n",
    "plt.xlabel(\"Popularity\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podrian eliminarse las canciones con pupularidad cerna a 0, tampco exageremos y borremos todas, pero cancion con una popularidad de 0 no nos inspira muchha confianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El box plot confirma una tendencia a valores mas altos de popularidad y tambien detecta algunos outliers. En el histograma se veia una concentracion de canciones con popularidad entre 0 y 5. No son canciones conocidas las que se concentran ahi pero nos resulta un poco raro. La variable en si es rara, no sabemos en base a que fue medida la popularidad de la cancion. Los valores pueden estar condicionados debido a que el dataset esta acotado a covers de los 90s, si los datos fueron recuperados cercanamente a la decada de los noventa por ejemplo los 2000s las personas escucharian estos covers mas que si nos alejaramos de los 90s y a medida que saldrian nuevas canciones y covers los valores se verian disminuidos  .Quizas recolectaron datos de otra aplicacion o de alguna plataforma de musica. Tampcoo sabemos que usaron de parametro para medirla, si las escuchas mensuales, discos vendidos, me gustas etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Danceability```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método ```value_counts()``` no se vió nada extraño. Por lo tanto, vamos a hacer un boxplot para ver mas en detalle la distribución de la variable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Nos quedamos solo con la columna Danceability\n",
    "danceability = covers_dataset[\"Danceability\"]\n",
    "\n",
    "# Creamos el boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=danceability)\n",
    "plt.title(\"Boxplot de Danceability\")\n",
    "plt.xlabel(\"Danceability\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "min = copy_covers_ds[\"Danceability\"].min()\n",
    "copy_covers_ds[copy_covers_ds[\"Danceability\"] == min]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que hay unos valores del lado izquierdo, podrian ser posibles outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar esta distribución de una forma más clara mediante un histograma"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 40\n",
    "\n",
    "plt.hist(copy_covers_ds['Danceability'], bins = bins)\n",
    "\n",
    "plt.xlabel('Danceability')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de la bailabilidad')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Vamos a mirar quiénes son las canciones que son poco bailables\n",
    "poco_bailables = copy_covers_ds[copy_covers_ds[\"Danceability\"] < 0.2]\n",
    "poco_bailables"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que, por ejemplo, \"Frozen\" de Madonna es una canción poco bailable. En particular, 3 de las 7 canciones menos bailables son también poco enérgicas, por lo que valdría la pena en un futuro análisis corroborar si existe una correlación fuerte entre ```Danceability``` y ```Energy```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Duration```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 40\n",
    "\n",
    "plt.hist(copy_covers_ds['DURATION(s)'], bins = bins)\n",
    "\n",
    "plt.xlabel('Duración (s)')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de duración de las canciones')\n",
    "plt.xticks(range(0, 450, 50))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que la mayoría de las canciones duran entre 150 y 300 segundos(2:30 y 5:00 minutos). Hay algunos outliers que superan los 500 segundos(8:33 minutos) y hay que corroborrar que sean correctos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "max = copy_covers_ds[\"DURATION(s)\"].max()\n",
    "copy_covers_ds[copy_covers_ds[\"DURATION(s)\"] == max]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corroboramos en internet que la canción dura 3:29 minutos, paro no meter mano en los datos podemos simplemente borrar estos tres outliers para que no molesten."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds[copy_covers_ds['DURATION(s)'] > 500]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda canción más larga es \"November Rain\" de Guns 'n Roses y su duración concuerda con el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos tomar como medida eliminar estos tres outliers que nos estan afectando la distribucion en la curva."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds = copy_covers_ds[copy_covers_ds['DURATION(s)'] < 500]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 40\n",
    "\n",
    "plt.hist(copy_covers_ds['DURATION(s)'], bins = bins)\n",
    "\n",
    "plt.xlabel('Duración (s)')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de duración de las canciones')\n",
    "plt.xticks(range(0, 450, 50))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Loudness```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 10\n",
    "\n",
    "plt.hist(copy_covers_ds['Loudness'], bins = bins)\n",
    "\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de loudness')\n",
    "plt.xticks(range(-50, 5, 5))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay algunos valores que son minoria abajo de -20db, veamos quienes son."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds[copy_covers_ds['Loudness'] < -20]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son en total 12 canciones, de las cuales hay un valor min. Cercano a -40."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "loudness = copy_covers_ds['Loudness']\n",
    "loudness.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay un valor minimo de -42. La verdad que no sabemos bien en base a que fue medida esta variable ni que usaron de referencia.\n",
    " Si sacamos concluciones podriamos decir que es una medida en base al umbral de audicion humano o es en base a que en 0db la cancion se deberia escuchar bien, en valores negativos bajo y en valores positivos alto.La primera opcion puede ser descartada ya que si seria en base a nuetra audicion un valor de -42db significaria que directamente no escuchamos la cancion cosa que no nos parece consistente.Consideremos entonces que es en base a una escala en la que 0 db es lo recomendado para que la cancion se escuche bien.Saquemos los valores dudosos!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds = covers_dataset[covers_dataset['Loudness'] > -20]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 10\n",
    "\n",
    "plt.hist(copy_covers_ds['Loudness'], bins = bins)\n",
    "\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de loudness')\n",
    "plt.xticks(range(-20, 5, 5))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gran mayoria de los valores se encuentran entre -10 y -5, y se puede apreciar un ligero sesgo hacia la izquierda. Igualmente nos resultan raro tantos valores de decibeles negativos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Instrumentalness```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 5\n",
    "\n",
    "plt.hist(copy_covers_ds['Instrumentalness'], bins = bins)\n",
    "\n",
    "plt.xlabel('Instrumentalness')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de Instrumentalizacion de las canciones')\n",
    "plt.xticks(np.arange(0, 1, 0.2))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podriamos discretizar la variable, por ejemplo utilizar una escala \"nula, baja, media, alta\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Creamos la nueva columna con las variable discretizada(todavia no hay nada) y la inicializamos en nulo.\n",
    "copy_covers_ds['Instrumentalness Type'] = pd.NA\n",
    "#Por cada registro hacemos:\n",
    "for index,row in copy_covers_ds.iterrows():\n",
    "    #Consideramos los 4 casos(intervalos) y asignamos el nueva valor segun corresponda\n",
    "    instrulmentalness_original = row['Instrumentalness']\n",
    "    if(instrulmentalness_original == 0):\n",
    "        instrulmentalness_nueva = 'nula'\n",
    "    elif(instrulmentalness_original > 0 and instrulmentalness_original <= 0.5 ) :\n",
    "        instrulmentalness_nueva = 'baja'\n",
    "    elif(instrulmentalness_original > 0.5 and instrulmentalness_original <= 1) :\n",
    "        instrulmentalness_nueva = 'alta'\n",
    "   \n",
    "        \n",
    "    copy_covers_ds.at[index,'Instrumentalness Type'] = instrulmentalness_nueva\n",
    "\n",
    "copy_covers_ds.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Contar la cantidad de cada tipo de 'Instrumentalness Type'\n",
    "instrumentalness_counts = copy_covers_ds['Instrumentalness Type'].value_counts()\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(8, 6))\n",
    "instrumentalness_counts.plot(kind='bar')\n",
    "plt.title('Distribución de Instrumentalness')\n",
    "plt.xlabel('Instrumentalness Type')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay muchas canciones con instrumentalizacion baja(cuidado que el intervalo para bajo es un poco mayor(0.1). Y que tambien hay muchas canciones con una instrumentalizacion nula(0 de instrumentalizacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Time Signature```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Contar la cantidad de cada tipo de 'Instrumentalness Type'\n",
    "Time_signature_counts = copy_covers_ds['Time_Signature'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "Time_signature_counts.plot(kind = 'bar')\n",
    "plt.yticks(range(0,901,100))\n",
    "plt.xticks(rotation = 0)\n",
    "plt.title('Cantidad de canciones por pulsaciones por compás')\n",
    "plt.xlabel('Signatura', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la gran mayoría de las canciones tienen 4 pulsaciones por compas, es un compás muy común según investigamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Liveness```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 10\n",
    "\n",
    "plt.hist(copy_covers_ds['Liveness'], bins = bins,color='green')\n",
    "\n",
    "plt.xlabel('Liveness')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de la Liveness de las canciones')\n",
    "plt.xticks(np.arange(0, 1, 0.1))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una distribucion muy sesgada hacia la derecha, lo que quiere decir que probablemente haya muchas canciones con poca presencia de la audiencia. Hay un par de valor que podrian ser posibles outliers ariba de 0.9 pero realmente no nos parece significante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Energy```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 10\n",
    "\n",
    "plt.hist(copy_covers_ds['Energy'], bins = bins,color='yellow')\n",
    "\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de la Energy de las canciones')\n",
    "plt.xticks(np.arange(0, 1, 0.1))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar una cuerva bastante sesgada hacia la derecha, lo que indica una gran presencia de canciones energéticas. Sinceramente como con muchas otras variables no sabemos como es que fueron medidas, como pasa en el caso de esta variable. ¿Como midieron la energia de la cancion? ¿estara ligada al ritmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas canciones con un valor de energía bajo son:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds[copy_covers_ds['Energy'] < 0.1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Nos quedamos solo con la columna Energy\n",
    "energy = covers_dataset[\"Energy\"]\n",
    "\n",
    "# Creamos el boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=energy)\n",
    "plt.title(\"Boxplot de Energy\")\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Key```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta variable es cuantitativa discreta, con valores de 0 a 11 y representan la clave de la canción, cada valor es una nota: Do Do# Re Re# Mi Fa Fa# Sol Sol# La La# Si \n",
    "\n",
    "La clave de una canción sería como la nota en la que se centra esa canción, el resto de las notas están alrededor de la misma. La clave es la nota en la que va a empezar la escala. Es como una nota de reposo, a la que volves al final porque si no se sentiría como que suena incompleto.\n",
    "\n",
    "Adjuntos dos videos que ayudan a entenderlo mejor: \n",
    "- [What does 'in the key of' mean? // Beginner music theory for piano](https://www.youtube.com/watch?v=h2k-NDPTL4o)\n",
    "- [Qué son las TONALIDADES. Tonalidad mayor y menor. | Jaime Altozano](https://www.youtube.com/watch?v=o6aOC3rERF0)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Contamos la cantidad de cada tipo de 'Key'\n",
    "key_counts = copy_covers_ds['Key'].value_counts().sort_index()\n",
    "\n",
    "# Creamos el gráfico de barras\n",
    "plt.figure(figsize=(8, 6))\n",
    "key_counts.plot(kind='bar')\n",
    "\n",
    "# Establecemos las etiquetas del eje x para las tonalidades(Time_Signature)\n",
    "plt.xticks(ticks=range(len(key_counts)), labels=['Do', 'Do#', 'Re', 'Re#', 'Mi', 'Fa', 'Fa#', 'Sol', 'Sol#', 'La', 'La#', 'Si'],rotation=0)\n",
    "\n",
    "plt.title('Distribución de Key')\n",
    "plt.xlabel('Key')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Contar la cantidad de cada tipo de 'Key' y ordenar por cantidad\n",
    "key_counts = copy_covers_ds['Key'].value_counts().sort_values()\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(8, 6))\n",
    "key_counts.plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Mapeo de índices a nombres de notas musicales\n",
    "notas = ['Do', 'Do#', 'Re', 'Re#', 'Mi', 'Fa', 'Fa#', 'Sol', 'Sol#', 'La', 'La#', 'Si']\n",
    "labels = [notas[i] for i in key_counts.index]  # Obtener las etiquetas correspondientes al índice ordenado\n",
    "\n",
    "# Configurar las etiquetas y el gráfico\n",
    "plt.xticks(ticks=range(len(key_counts)), labels=labels, rotation=0)\n",
    "plt.title('Distribución de Key')\n",
    "plt.xlabel('Key')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar el histograma podemos ver que las Key que tienen más canciones son la clave de [Do#](https://youtu.be/TpYeSEIONG8?t=22) y [Sol](https://youtu.be/tFTM7e4VjJw?t=30), y la que tiene menos canciones es la clave de [Re#](https://youtu.be/v3bBZcUQKJ0?t=29).\n",
    "\n",
    "Sin embargo, luego de esta investigación nos dimos cuenta qué no podemos analizar la clave sin el tono. Las claves pueden estar en tono mayor o menor, y eso lo hace sonar más alegre o más triste respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisis de Key con Mode que nadie pidio: "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "key_mode = copy_covers_ds[['Key', 'Mode']]\n",
    "#key_mode['Key+Mode'] = \n",
    "\n",
    "key_counts = copy_covers_ds['Key'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "#key_counts.plot(kind='bar', color='skyblue')\n",
    "\n",
    "notas = ['Do', 'Do#', 'Re', 'Re#', 'Mi', 'Fa', 'Fa#', 'Sol', 'Sol#', 'La', 'La#', 'Si']\n",
    "labels = [notas[i] for i in key_counts.index]\n",
    "\n",
    "sns.histplot(data=key_mode, x='Key', hue='Mode', multiple='dodge', discrete=True, shrink=0.8)\n",
    "plt.title('Histograma Key diferenciado por Mode')\n",
    "plt.xlabel('Key')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.xticks(ticks=range(len(key_counts)), labels=labels, rotation=0)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si podemos ver Key diferenciada por modo. Como aca se ve y más adelante se vuelve a mencionar, hay muchas más canciones en tono mayor que menor.\n",
    "\n",
    "De las canciones en tono mayor, de las que más hay es en clave Sol, Do# y Do.\n",
    "\n",
    "De las canciones en tono menor, de las que más hay es en clave Si, Fa y La#."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Speechiness```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es la medida de presencia de palabras habladas en las canciones, valores altos indican una alta presencia de estas palabras."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds['Speechiness'].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una variable cuantitativa continua\n",
    "\n",
    "De la funcion describe() se puede ver que hasta el 75% de los datos son valores muy bajos debajo de 0.1\n",
    "\n",
    "Esto podria significar que la mayoria de las canciones no tienen casi palabras habladas. Con palabras habladas pensamos que una cancion con valores altos seria una cancion de rap por ejemplo. \n",
    "\n",
    "Aunque tampoco hay ninguna que sea totalmente hablada, ya que el maximo llega a 0.529."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 15\n",
    "\n",
    "plt.hist(copy_covers_ds['Speechiness'], bins = bins)\n",
    "\n",
    "plt.xlabel('Speechiness')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Histograma de Speechiness')\n",
    "plt.xticks(np.arange(0, 1, 0.1))\n",
    "plt.yticks(range(0,601,50))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de realizar el histograma volvemos a confirmar que hay muchisimas canciones con valores bajos."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.boxplot(copy_covers_ds['Speechiness'])\n",
    "plt.ylabel('Speechiness')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el boxplot para ver si quizas habia un valor solo alejado, pero en verdad esta distribuido medio parejo los valores mas alla del 75%. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "max = copy_covers_ds[\"Speechiness\"].max()\n",
    "copy_covers_ds[copy_covers_ds[\"Speechiness\"] == max]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "min = copy_covers_ds[\"Speechiness\"].min()\n",
    "copy_covers_ds[copy_covers_ds[\"Speechiness\"] == min]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para chusmear un poco más, la cancion con el maximo de Speechiness es algo como Hip Hop, Pop Rap según lo que buscamos. Tiene sentido quiza que este ahi pero tampoco es que sea re hablada, es un valor de 0.529.\n",
    "\n",
    "Y la cancion con el minimo de Speechiness tiene una onda triste, lenta y bien cantada. Pd: descubrimos que la artista es la que canta \"When She Loved Me\" de Toy Story 2 c':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Mode```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos una variable categórica, podemos modelarla mediante un gráfico de barras, donde podamos apreciar la cantidad de canciones de cada categoría"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Contamos la cantidad de canciones de cada tipo\n",
    "mode_values = copy_covers_ds['Mode'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "mode_values.plot(kind='pie', labels=['Tono mayor', 'Tono menor'])\n",
    "plt.title('Cantidad de canciones según su modo')\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('Mode')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia que hay muchas más canciones escritas en escala mayor que en escala menor. Según esta [página](https://www.artsmusica.net/teoria-musical/diferencia-entre-escalas-mayores-y-menores/), una canción compuesta por una escala mayor da una sensación de alegría, mientras que a las que se conforman por escalas menores se les atribuye sentimientos más tristes o depresivos. Por lo tanto, sería de especial interés comprobar si existe una relación entre ```Mode``` con la variable que mide los niveles de positividad de la canción, ```Valance```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Acoustiness```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a realizar el análisis sobre la variable que mide que tan acústica es una canción. Como se trata de una variable cuantitativa continua, vamos a discretizarla de manera tal de poder modelar su distribución en un histograma y/o boxplot "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds['Acousticness'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds['Acousticness'].describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Como se puede ver, el 75% de los datos se encuentran en el rango de 0.00 a 0.34 aprox mientras que el otro 25% se encuentra entre 0.34 y 0.99, por lo tanto, si se la grafica se podría apreciar un sesgo a derecha debido a ese porcentaje de datos restante\n",
    "* Aunque la mayoría de los datos son pequeños, hay cierta dispersión y unos cuantos valores más altos que contribuyen a que la desviación estándar un poco más alta en comparación con la media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que conocemos la distribución de los datos, podemos optar por realizar una discretización de la variable de dos formas: equal-depth o entropy-based(equal-width no debido a que no maneja bien distribuciones sesgadas)<br>\n",
    "Como tenemos 919 datos, podemos hacer 20 intervalos con, aproximadamente, 46 valores en cada uno"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ordenamos los datos\n",
    "acousticness_sort = copy_covers_ds['Acousticness'].sort_values()\n",
    "\n",
    "# Definimos el número de intervalos (bins)\n",
    "bins = 20\n",
    "\n",
    "# Graficamos el histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(acousticness_sort, bins=bins)\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Histograma de Acousticness')\n",
    "plt.xlabel('Acousticness')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.xticks(np.arange(0,1.05,0.05))\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n",
    "##"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico confirma lo que ya pensabamos, existe un fuerte sesgo a derecha. La mayoría de las canciones tienen un nivel acústico muy leve. Es decir, pocas canciones usan instrumentos acústicos(ej: violin, corno francés, trombón, saxofón, guitarra acústica, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Year```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El año de lanzamiento es una variable de tipo cuantitativa discreta. Debido a que es un dataset de los años '90, tenemos canciones del 90 al 99."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Year_counts = copy_covers_ds['Year'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "Year_counts.plot(kind='bar')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.title('Cantidad de canciones por año de lanzamiento')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que se lanzaron más canciones en el año 1991, y menos en el 1996. En un futuro podríamos ver como se relaciona esto con la popularidad de las canciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Tempo```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La velocidad de la pista es una variable cuantitativa continua, por lo que podemos modelarla mediante un histograma"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds['Tempo'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ordenamos los datos\n",
    "tempo_sort = copy_covers_ds['Tempo'].sort_values()\n",
    "\n",
    "# Definimos el número de intervalos (bins)\n",
    "bins = 20\n",
    "\n",
    "# Graficamos el histograma\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(tempo_sort, bins=bins)\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Histograma de Tempo')\n",
    "plt.xlabel('Tempo')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "#plt.xticks(range(45,230,10))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "# Mostramos el gráfico\n",
    "plt.show()\n",
    "##"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el histograma y, según información que encontramos en [esta fuente](https://hacercanciones.com/tutorial/el-tempo-y-la-musica/), la mayoría de las canciones tienen un ritmo medio tendiendo a rápido.<br>\n",
    "La canción más rápida es:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "max = copy_covers_ds[\"Tempo\"].max()\n",
    "copy_covers_ds[copy_covers_ds[\"Tempo\"] == max]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y la más lenta:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "min = copy_covers_ds[\"Tempo\"].min()\n",
    "copy_covers_ds[copy_covers_ds[\"Tempo\"] == min]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dando una escucha a ambas canciones no nos pareció que ninguna correspondía al tempo registrado en el dataset. ¿Quizás los covers que se hicieron sobre esas canciones estaban en distinto tempo respecto al original? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Análisis bivariado y multivariado<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los resultados obtenidos mediante el análisis univariado realizado previamente, sacamos distintas hipótesis sobre las variables que podrían ser de sumo interés para sacar conclusiones de valor. Ahora nos centraremos en indagar sobre la veracidad de esas suposiciones mediante un análisis bivariado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Valence vs Tempo```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un pensamiento fácil sería decir que dependiendo del nivel de positividad de la canción(Valence), una canción puede ser más rápida o más lenta(Tempo). Podemos comprobar si se cumple para el dataset dado"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Valence'], copy_covers_ds['Tempo'])[0,1]\n",
    "\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Valence'], copy_covers_ds['Tempo'], label=f'Correlacion {coeficiente_correlacion}', color='black')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su positividad\")\n",
    "plt.ylabel(\"Velocidad de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Valence y Tempo\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostramos el gráfico de dispersión\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De primeras no podemos observar nada con el Scatter Plot. Podemos separar Valance en varios grupos para analiza el tempo promedio dentro de cada grupo. Primero observaremos la distribución de Valence para poder identificar los grupos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ordenamos los datos\n",
    "valence_sort = copy_covers_ds['Valence'].sort_values()\n",
    "\n",
    "# Definimos el número de intervalos (bins)\n",
    "bins = 30\n",
    "\n",
    "# Graficamos el histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(valence_sort, bins=bins)\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Histograma de Valence')\n",
    "plt.xlabel('Valence')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.xticks(np.arange(0,1,0.1))\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una buena medición sería tomar tres grupos: de 0.0 a 0.3(baja positividad), de 0.3 a 0.6(media positividad) y de 0.6 a 1.0(alta positividad)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Hamos los bins para separar los grupos\n",
    "bins = [0.0, 0.3, 0.6, 1.0]\n",
    "#Definimos las labels\n",
    "labels = ['baja_positividad', 'media_positividad', 'alta_positividad']\n",
    "#Armamos los grupos\n",
    "copy_covers_ds['Valence_groups']= pd.cut(copy_covers_ds['Valence'], bins=bins, labels=labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el boxplot para ver las distribuciones de los grupos de Valence en Tempo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Crear el boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([copy_covers_ds[copy_covers_ds[\"Valence_groups\"] == \"baja_positividad\"][\"Tempo\"],\n",
    "             copy_covers_ds[copy_covers_ds[\"Valence_groups\"] == \"media_positividad\"][\"Tempo\"],\n",
    "             copy_covers_ds[copy_covers_ds[\"Valence_groups\"] == \"alta_positividad\"][\"Tempo\"]],\n",
    "             tick_labels=[\"Baja\", \"Media\", \"Alta\"], notch=True)\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "plt.xlabel(\"Nivel de positividad de la canción\")\n",
    "plt.ylabel(\"Velocidad\")\n",
    "\n",
    "# Agregar un título al gráfico\n",
    "plt.title(\"Distribución de positividad de la canción vs. velocidad\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en la información del box plot parece no haber una diferencia significativa entre los grupos. Comprobaremos si esto es o no así con alguna prueba estadística como ANOVA o Kruskal-Wallis. Primero, verifiquemos normalidad en los grupos con Shapiro-Wilks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Separamos los datos en tres grupos, poca energia, media energia y alta energia\n",
    "poca_positividad = copy_covers_ds[copy_covers_ds['Valence_groups'] == 'baja_positividad']['Tempo']\n",
    "media_positividad = copy_covers_ds[copy_covers_ds['Valence_groups'] == 'media_positividad']['Tempo']\n",
    "alta_positividad = copy_covers_ds[copy_covers_ds['Valence_groups'] == 'alta_positividad']['Tempo']\n",
    "\n",
    "# Test de Shapiro-Wilk para poca energia\n",
    "stat, p = shapiro(poca_positividad)\n",
    "print(f\"Test de Shapiro-Wilk para poca positividad: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Test de Shapiro-Wilk para media energia\n",
    "stat, p = shapiro(media_positividad)\n",
    "print(f\"Test de Shapiro-Wilk para media positividad Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Test de Shapiro-Wilk para alta energia\n",
    "stat, p = shapiro(alta_positividad)\n",
    "print(f\"Test de Shapiro-Wilk para alta positividad: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, los datos no respetan una distribución normal. Comprobaremos la homocedastecidad de los datos mediante el test de Levene. De esta manera podremos determinar si existe una diferencia significativa entre las varianzas de los grupos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import scipy.stats as stats\n",
    "stat, p = stats.levene(poca_positividad, media_positividad, alta_positividad)\n",
    "print(f\"Test de Levene para grupos de energia: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El test de Levene nos dice que las variazas no son significativamente diferentes entre sí(son homocedásticos). Podemos aplicar Kruskal-Wallis para ver si existen diferencias significativas en Tempo entre los grupos de Valence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import scipy.stats as stats\n",
    "# Test de Kruskal-Wallis para comparar el tempo  entre canciones con distintos niveles de positividad\n",
    "stat, p = stats.kruskal(poca_positividad, media_positividad, alta_positividad)\n",
    "print(f\"Test de Kruskal-Wallis para Tempo: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en el nivel de bailabilidad entre canciones con distintos niveles de energía.\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en el nivel de bailabilidad entre canciones con distintos niveles de energía.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, podemos concluir con que no hay evidencia suficiente para apoyar la hipótesis de que las canciones más positivas tienen tempos más altos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Liveness vs Popularity```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Popularity'], copy_covers_ds['Liveness'])[0,1]\n",
    "\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Popularity'], copy_covers_ds['Liveness'], label=f'Correlacion {coeficiente_correlacion}', color='orange')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su Popularidad\")\n",
    "plt.ylabel(\"Velocidad de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Popularidad y Viveza\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostramos el gráfico de dispersión\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No importaba que p valor planteramos que nustras hipotesis seria rechazada, si supondriamos una confianza del 0.95 o de 0.7 no llegabamos ni aunque quiesieramos. El valor de correlacion muy cercano a 0 supondria que ambas variables son altamente independientes entre si o tienen un relacion que no es lineal. En el Scatter plot si miramos bien muy difusamente se puede ver una especie de parabola aunque no bien definida. Lo que si podemos asegurar es que no existe una relacion lineal entre ambas. Una mayor presencia de audiencia en el track no supone una mayor popularidad."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Sacamos todo lo que no sea continuo y lo que vamos a pintar\n",
    "X = copy_covers_ds.drop(['Duration', 'Mode','Track','Artist','Key','Year','Popularity','Instrumentalness Type', 'Valence_groups'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#\n",
    "pca = PCA(n_components=2, whiten=False)\n",
    "\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "print('Antes de PCA: {}'.format(X.shape))\n",
    "print('Después de PCA: {}'.format(principalComponents.shape))\n",
    "\n",
    "\n",
    "plt.scatter(principalComponents[:,0], principalComponents[:,1])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Proyección PCA 1')\n",
    "plt.ylabel('Proyección PCA 2')\n",
    "plt.title('Proyección del conjunto de datos a 2 dimensiones')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca.__dict__"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "plt.scatter(principalComponents[:,0], principalComponents[:,1], c=copy_covers_ds[\"Popularity\"], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Proyección PCA 1')\n",
    "plt.ylabel('Proyección PCA 2')\n",
    "plt.title('Proyección del conjunto de datos a 2 dimensiones')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# importamos el t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "X_tsne = TSNE(n_components=2, random_state=10).fit_transform(X_scaled)  \n",
    "\n",
    "\n",
    "print('Before t-SNE: {}'.format(X_scaled.shape))\n",
    "print('After t-SNE: {}'.format(X_tsne.shape))\n",
    "\n",
    "\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1], c=copy_covers_ds[\"Popularity\"], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Componente 1 t-SNE')\n",
    "plt.ylabel('Component 2 t-SNE')\n",
    "plt.title('Representación t-SNE del conjunto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que en ambos casos no hay una relacion entre las demas caracteristicas del dataset y la popularidad."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ordenamos los datos\n",
    "popularity_sort = copy_covers_ds['Popularity'].sort_values()\n",
    "\n",
    "# Definimos el número de intervalos (bins)\n",
    "bins = 20\n",
    "\n",
    "# Graficamos el histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(popularity_sort, bins=bins, color='yellow', edgecolor='orange')\n",
    "\n",
    "# Añadimos título y etiquetas\n",
    "plt.title('Histograma de Popularity')\n",
    "plt.xlabel('Popularity')\n",
    "plt.ylabel('Cantidad de canciones')\n",
    "plt.xticks(np.arange(0,100,5))\n",
    "\n",
    "# Mostramos el gráfico\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos separar por la moda. Para hacer un analisis de que tan significativa estadisticamente es la diferencia entre el promedio de liveness entre ambos grupos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "copy_covers_ds['Popularity_groups'] = pd.NA\n",
    "#Por cada registro hacemos:\n",
    "for index,row in copy_covers_ds.iterrows():\n",
    "    \n",
    "    popularidad = row['Popularity']\n",
    "    if popularidad >= 65:\n",
    "        popularity_group = 'upper_group'\n",
    "    elif popularidad < 65:\n",
    "        popularity_group = 'lower_group'\n",
    "        \n",
    "    copy_covers_ds.at[index,'Popularity_groups'] = popularity_group"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.boxplot(x='Popularity_groups', y='Liveness', data=copy_covers_ds, notch=True)\n",
    "plt.title(\"Viveza por popularidad de la cancion\")\n",
    "plt.xlabel(\"Grupo de popularidad\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Debajo de la moda\", \"Por encima de la moda\"])\n",
    "plt.ylabel(\"Liveness\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un monton de outliers! Ya por el acogotamiento se podria decir que la diferencia no va a ser significativa. Pero vamos a darle un toque mas empirico al analisis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds = copy_covers_ds[copy_covers_ds['Liveness'] < 0.4]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sns.boxplot(x='Popularity_groups', y='Liveness', data=copy_covers_ds, notch=True)\n",
    "plt.title(\"Viveza por popularidad de la cancion\")\n",
    "plt.xlabel(\"Grupo de popularidad\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Debajo de la moda\", \"Por encima de la moda\"])\n",
    "plt.ylabel(\"Liveness\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "upper_mode_songs = copy_covers_ds[copy_covers_ds['Popularity_groups'] == 'upper_group']['Liveness']\n",
    "lower_mode_songs = copy_covers_ds[copy_covers_ds['Popularity_groups'] == 'lower_group']['Liveness']\n",
    "\n",
    "\n",
    "stat, p = shapiro(upper_mode_songs)\n",
    "print(f\"Test de Shapiro-Wilk para canciones por encima de la moda: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "\n",
    "stat, p = shapiro(lower_mode_songs)\n",
    "print(f\"Test de Shapiro-Wilk para canciones por debajo de la mdoa: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p valores muy cercanos a 0, no son normales. Chau test t. Veamos homocedasticidad."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import scipy.stats as stats\n",
    "stat, p = stats.levene(upper_mode_songs, lower_mode_songs)\n",
    "print(f\"Test de Levene para Liveness entre ambos grupos de canciones: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p valor por encima de 0.05, que alegria!! yuppie!!, se corrobora que son homocedasticos. Hagamos Mann Whitney!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "stat, p = stats.mannwhitneyu(upper_mode_songs, lower_mode_songs)\n",
    "print(f\"Test de Mann-Whitney : Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en en Liveness de las canciones por encima de la moda y por debajo\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en el Liveness en las canciones por encima de la moda y por debajo\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habiamo predicho al inicio desde el analisis visual del acogotamiento de los box plots no existe una diferencia significativa para poder asegurar que el liveness de las canciones es diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero no nos rindamos aca!, puede haber una relacion entre liveness y el Mode(tono mayor o tono menor) de las canciones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.boxplot(x='Mode', y='Liveness', data=copy_covers_ds, notch=True)\n",
    "plt.title(\"Viveza por Modo de la cancion\")\n",
    "plt.xlabel(\"Modo\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Tono menor\", \"Tono mayor\"])\n",
    "plt.ylabel(\"Liveness\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds = copy_covers_ds[copy_covers_ds['Liveness'] < 0.4]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sns.boxplot(x='Mode', y='Liveness', data=copy_covers_ds, notch=True)\n",
    "plt.title(\"Viveza por Modo de la cancion\")\n",
    "plt.xlabel(\"Modo\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"Tono menor\", \"Tono mayor\"])\n",
    "plt.ylabel(\"Liveness\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "tono_alto = copy_covers_ds[copy_covers_ds['Mode'] == 1]['Liveness']\n",
    "tono_bajo = copy_covers_ds[copy_covers_ds['Mode'] == 0]['Liveness']\n",
    "\n",
    "\n",
    "stat, p = shapiro(tono_alto)\n",
    "print(f\"Test de Shapiro-Wilk para canciones con tono alto: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "\n",
    "stat, p = shapiro(tono_bajo)\n",
    "print(f\"Test de Shapiro-Wilk para canciones con tono bajo: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es normal! :("
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "stat, p = stats.levene(tono_alto, tono_bajo)\n",
    "print(f\"Test de Levene para Liveness: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No son homosedasticos, hay que ir a los no parametricos! : Kruskal Wallis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "stat, p = stats.kruskal(tono_alto, tono_bajo)\n",
    "print(f\"Test de Kruskal-Wallis para Liveness: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en el Liveness entre canciones de tono alto y tono bajo.\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en el Liveness entre canciones de tono alto y tono bajo.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver no llegamos a nada, la diferencia no es la suficiente como para poder asegurar algo! que triste..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de ```Danceability vs Energy```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "variable_1 = \"Energy\"\n",
    "variable_2 = \"Danceability\"\n",
    "\n",
    "# Extraer las columnas del DataFrame\n",
    "datos_columna1 = copy_covers_ds[variable_1]\n",
    "datos_columna2 = copy_covers_ds[variable_2]\n",
    "\n",
    "# creamos el scatter plot\n",
    "plt.figure(figsize=(6, 6))  \n",
    "plt.scatter(copy_covers_ds[variable_1], copy_covers_ds[variable_2])\n",
    "plt.xlabel(variable_1)\n",
    "plt.ylabel(variable_2)\n",
    "plt.title(\"Relación entre {} y {}\".format(variable_1, variable_2))\n",
    "\n",
    "# calcular la correlación de Pearson usando SciPy\n",
    "coeficiente_correlacion, _ = stats.pearsonr(datos_columna1, datos_columna2)\n",
    "# agregar la leyenda con el valor del coeficiente de correlación\n",
    "plt.legend([f\"Correlación: {coeficiente_correlacion:.4f}\"], loc=\"upper left\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista solo se ve una nube de puntos sin direccion. La correlacion dda muy baja, del 0.13. No logramos detectar visualmente si podria llegar a existir otro tipo de relacion que no sea lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos probar a ver si existen grupos dentro de Energy "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bins = 50\n",
    "\n",
    "plt.hist(copy_covers_ds['Energy'], bins = bins)\n",
    "\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de energy')\n",
    "plt.xticks(np.arange(0, 1, 0.1))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos separarlo en 3 grupos. Uno que vaya de 0.0 a 0.3(baja energia), otro de 0.3 a 0.6(energia media) y de 0.6 a 1.0(mucha energia)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Hamos los bins para separar los grupos\n",
    "bins = [0.0, 0.3, 0.6, 1.0]\n",
    "#Definimos las labels\n",
    "labels = ['baja_energia', 'media_energia', 'alta_energia']\n",
    "#Armamos los grupos\n",
    "copy_covers_ds['Energy_groups']= pd.cut(copy_covers_ds['Energy'], bins=bins, labels=labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos un boxplot para comparar la variabilidad de cada grupo respecto a los valores de Danceability"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Crear el boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([copy_covers_ds[copy_covers_ds[\"Energy_groups\"] == \"baja_energia\"][\"Danceability\"],\n",
    "             copy_covers_ds[copy_covers_ds[\"Energy_groups\"] == \"media_energia\"][\"Danceability\"],\n",
    "             copy_covers_ds[copy_covers_ds[\"Energy_groups\"] == \"alta_energia\"][\"Danceability\"]],\n",
    "             tick_labels=[\"Baja\", \"Media\", \"Alta\"], notch=True)\n",
    "\n",
    "# Agregar etiquetas a los ejes\n",
    "plt.xlabel(\"Nivel de energia\")\n",
    "plt.ylabel(\"Nivel de bailabilidad\")\n",
    "\n",
    "# Agregar un título al gráfico\n",
    "plt.title(\"Distribución de energia de la canción vs. nivel de bailabilidad\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que existe una diferencia significativa entre el primer grupo y los demás. Sin embargo, no existe tal diferencia entre el grupo dos y el tres\n",
    "Para ver si existen o no diferencias estadísticamente significativas entre los grupos con ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tendremos que verificar los supuestos de ANOVA. Empezaremos con la normalidad de los datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Separamos los datos en tres grupos, poca energia, media energia y alta energia\n",
    "poca_energia = copy_covers_ds[copy_covers_ds['Energy_groups'] == 'baja_energia']['Danceability']\n",
    "media_energia = copy_covers_ds[copy_covers_ds['Energy_groups'] == 'media_energia']['Danceability']\n",
    "alta_energia = copy_covers_ds[copy_covers_ds['Energy_groups'] == 'alta_energia']['Danceability']\n",
    "\n",
    "# Test de Shapiro-Wilk para poca energia\n",
    "stat, p = shapiro(poca_energia)\n",
    "print(f\"Test de Shapiro-Wilk para poca energia: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Test de Shapiro-Wilk para media energia\n",
    "stat, p = shapiro(media_energia)\n",
    "print(f\"Test de Shapiro-Wilk para media energia Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Test de Shapiro-Wilk para alta energia\n",
    "stat, p = shapiro(alta_energia)\n",
    "print(f\"Test de Shapiro-Wilk para alta energia: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un QQ-plot para hacer la comprobación de normalidad"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "# QQ plot para energia baja\n",
    "stats.probplot(poca_energia, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot para la bailabilidad de la canción según energia baja\")\n",
    "plt.show()\n",
    "\n",
    "# QQ plot para energia media\n",
    "stats.probplot(media_energia, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot para la bailabilidad de la canción según energia media\")\n",
    "plt.show()\n",
    "\n",
    "#QQ plot para energia alta\n",
    "stats.probplot(alta_energia, dist=\"norm\", plot=plt)\n",
    "plt.title(\"QQ Plot para la bailabilidad de la canción según energia alta\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusión, ni Shapiro ni el QQ-plot nos están mostrando normalidad en los datos, así que no podemos usar el test de ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobaremos la homocedastecidad de los datos mediante el test de Levene. De esta manera podremos determinar si existe una diferencia significativa entre las varianzas de los grupos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "stat, p = stats.levene(poca_energia, media_energia, alta_energia)\n",
    "print(f\"Test de Levene para grupos de energia: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el test de Levene comprobamos que existe homocedasticidad en los grupos. Por lo tanto podemos aplicar el test de Kruskal-Wallis para conocer si son o no estadísticamente diferentes entre sí"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test de Kruskal-Wallis para comparar el nivel de bailabilidad entre canciones con distintos niveles de energía\n",
    "stat, p = stats.kruskal(poca_energia, media_energia, alta_energia)\n",
    "print(f\"Test de Kruskal-Wallis para Danceability: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en el nivel de bailabilidad entre canciones con distintos niveles de energía.\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en el nivel de bailabilidad entre canciones con distintos niveles de energía.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, podemos afirmar que existen diferencias significativas entre los grupos. Es decir que efectivamente, para niveles más bajos de energía, las canciones son menos bailables y, para niveles más altos, las canciones tienen características que las hacen más bailables\n",
    "Se ve una gran diferencia entre el nivel más bajo de energía con el nivel más alto, pero no tento entre el nivel medio y el más alto, cosa que a primeras parece un poco sospechoso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Valence vs Mode```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora analizaremos la relación que existe entre el nivel de positividad de la canción y el tono en el que se escribió(mayor o menor)<br>\n",
    "Para ello, dividiremos la variable Valance según el Mode(0 o 1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filtrar las canciones en modo menor (Mode = 0) y modo mayor (Mode = 1)\n",
    "valence_menor = copy_covers_ds[copy_covers_ds['Mode'] == 0]['Valence']\n",
    "valence_mayor = copy_covers_ds[copy_covers_ds['Mode'] == 1]['Valence']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "valence_menor.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "valence_mayor.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver observando los valores de media y mediana que, en promedio, las canciones en modo menor tienen un Valence (positividad) ligeramente superior, aunque la diferencia es pequeña<br>\n",
    "La desviación estándar es similar en ambos grupos (0.23 para menor y 0.25 para mayor), es decir, la variabilidad es comparable.<br>\n",
    "Dado que las medias y medianas no difieren significativamente a simple vista, una prueba de Mann-Whitney o un test T podría confirmar si estas diferencias son significativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer un boxplot para ver esta diferencia de forma gráfica"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6, 6)) \n",
    "plt.boxplot([copy_covers_ds[copy_covers_ds['Mode'] == 0]['Valence'], copy_covers_ds[copy_covers_ds['Mode'] == 1]['Valence']], tick_labels=[\"Menor\", \"Mayor\"], notch=True)\n",
    "# Agregar etiquetas a los ejes\n",
    "plt.xlabel(\"Modo de la canción\")\n",
    "plt.ylabel(\"Positividad\")\n",
    "\n",
    "# Agregar un título al gráfico\n",
    "plt.title(\"Distribución de la variable Valance según el Modo\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, las diferencias son poco apreciables pero hay que ver si estadísticamente son significativas o no"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Test de Shapiro-Wilk para valence con modo menor\n",
    "stat, p = shapiro(valence_menor)\n",
    "print(f\"Test de Shapiro-Wilk para poca energia: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Test de Shapiro-Wilk para valence con modo mayor\n",
    "stat, p = shapiro(valence_mayor)\n",
    "print(f\"Test de Shapiro-Wilk para media energia Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no comprobamos normalidad, no podemos tirarnos por hacer un test t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que no se comprobó normalidad para el test T, solo nos queda probar con Mann-Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test de Mann-Whitney U para comparar Valence entre modo menor y modo mayor(escala menor y mayor)\n",
    "stat, p = stats.mannwhitneyu(valence_menor, valence_mayor)\n",
    "print(f\"Test de Mann-Whitney U para Valence : Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en las canciones entre escala mayor o menor.\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en las canciones entre escala mayor o menor.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por consiguiente, podemos asegurar que las diferencias en las canciones con modo mayor y menor son estadísticamente significativas<br>\n",
    "Esto sugiere que, en general, las canciones en escala menor tienden a ser más positivas más alto, lo que implica que podrían ser percibidas como más positivas o alegres que las canciones en escala mayor. Es decir que se confirmó lo contrario a lo que suponíamos. Realmente interesante😲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Loudness vs Energy```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos ver si la medida de ruido de la canción está relacionada o no con los niveles de energía que posee. Podemos hacer un scatter plot para ver si están correlacionadas linealmente"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Loudness'], copy_covers_ds['Energy'])[0,1]\n",
    "\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Loudness'], copy_covers_ds['Energy'], label=f'Correlacion {coeficiente_correlacion}')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su nivel de ruidosidad\")\n",
    "plt.ylabel(\"Energía de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Loudness y Energy\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostramos el gráfico de dispersión\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay una tendencia cuadrática positiva en el gráfico ¿Quizás haya otra relación que no sea lineal?\n",
    "También podríamos eliminar los outliers que aparecen para ver si están alterando el verdadero valor de la correlación"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Nos quedmos solo con los valores superiores a -25\n",
    "copy_covers_ds = copy_covers_ds[copy_covers_ds['Loudness'] > -25]\n",
    "\n",
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Loudness'], copy_covers_ds['Energy'])[0,1]\n",
    "\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Loudness'], copy_covers_ds['Energy'], label=f'Correlacion {coeficiente_correlacion}')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su nivel de ruidosidad\")\n",
    "plt.ylabel(\"Energía de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Loudness y Energy\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostramos el gráfico de dispersión\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora eliminando los outliers podemos notar un poco más de presencia lineal en la correlación, lo que podría sugerir que a medida que aumenta la ruidosidad de la canción aumenta los niveles de energía(hipótesis). Sin embargo, para ver si esta correlación es estadísticamente significativa, podemos realizar una prueba de hipótesis usando una prueba de correlación de Pearson"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "coeficiente_correlacion, p_valor = pearsonr(copy_covers_ds['Loudness'], copy_covers_ds['Energy'])\n",
    "print(f\"Coeficiente de correlación: {coeficiente_correlacion}\")\n",
    "print(f\"p-valor: {p_valor}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el p-valor dió muy por debajo de los 0.05 indica que la correlación es estadísticamente significativa entre las variables, es decir, la relación no se dio de forma aleatoria e indica una relación real entre ellas. Por lo tanto, esto implica que las canciones con mayor nivel de ruidosidad tienden a ser también las que presentan niveles de energía más altos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```¿Tempo,valence y energy determinan el modo de la cancion?```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Sacamos todo lo que no sea continuo y lo que vamos a pintar\n",
    "X = pd.concat([copy_covers_ds['Tempo'],copy_covers_ds['Energy'],copy_covers_ds['Valence']],axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#\n",
    "pca = PCA(n_components=2, whiten=False)\n",
    "\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "print('Antes de PCA: {}'.format(X.shape))\n",
    "print('Después de PCA: {}'.format(principalComponents.shape))\n",
    "\n",
    "\n",
    "plt.scatter(principalComponents[:,0], principalComponents[:,1])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Proyección PCA 1')\n",
    "plt.ylabel('Proyección PCA 2')\n",
    "plt.title('Proyección del conjunto de datos a 2 dimensiones')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.scatter(principalComponents[:,0], principalComponents[:,1], c=copy_covers_ds[\"Mode\"], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Proyección PCA 1')\n",
    "plt.ylabel('Proyección PCA 2')\n",
    "plt.title('Proyección del conjunto de datos a 2 dimensiones')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca.__dict__"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# importamos el t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "X_tsne = TSNE(n_components=2, random_state=10).fit_transform(X_scaled)  \n",
    "\n",
    "\n",
    "print('Before t-SNE: {}'.format(X_scaled.shape))\n",
    "print('After t-SNE: {}'.format(X_tsne.shape))\n",
    "\n",
    "\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1], c=copy_covers_ds[\"Mode\"], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Componente 1 t-SNE')\n",
    "plt.ylabel('Component 2 t-SNE')\n",
    "plt.title('Representación t-SNE del conjunto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Tempo'], copy_covers_ds['Energy'])\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Tempo'], copy_covers_ds['Energy'],c=copy_covers_ds[\"Danceability\"], cmap='viridis', label=f'Correlacion {coeficiente_correlacion}')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su nivel de Tempo\")\n",
    "plt.ylabel(\"Energía de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Tempo y Energy\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostramos el gráfico de dispersión\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Sacamos todo lo que no sea continuo y lo que vamos a pintar\n",
    "X = pd.concat([copy_covers_ds['Tempo'],copy_covers_ds['Energy'],copy_covers_ds['Danceability']],axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#\n",
    "pca = PCA(n_components=2, whiten=False)\n",
    "\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "print('Antes de PCA: {}'.format(X.shape))\n",
    "print('Después de PCA: {}'.format(principalComponents.shape))\n",
    "\n",
    "\n",
    "plt.scatter(principalComponents[:,0], principalComponents[:,1],c=copy_covers_ds['Popularity'], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Proyección PCA 1')\n",
    "plt.ylabel('Proyección PCA 2')\n",
    "plt.title('Proyección del conjunto de datos a 2 dimensiones')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca.__dict__"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_tsne = TSNE(n_components=2, random_state=10).fit_transform(X_scaled)  \n",
    "\n",
    "\n",
    "print('Before t-SNE: {}'.format(X_scaled.shape))\n",
    "print('After t-SNE: {}'.format(X_tsne.shape))\n",
    "\n",
    "\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1], c=copy_covers_ds[\"Danceability\"], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Componente 1 t-SNE')\n",
    "plt.ylabel('Component 2 t-SNE')\n",
    "plt.title('Representación t-SNE del conjunto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Speechiness'], copy_covers_ds['Instrumentalness'])\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Speechiness'], copy_covers_ds['Instrumentalness'],c=copy_covers_ds[\"Popularity\"], cmap='viridis', label=f'Correlacion {coeficiente_correlacion}')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su nivel de Speechieness\")\n",
    "plt.ylabel(\"Instrumentalness de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Speechieness y Instrumentalness\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostramos el g"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Energy'], copy_covers_ds['Speechiness'])\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Energy'], copy_covers_ds['Speechiness'],c=copy_covers_ds[\"Loudness\"], cmap='viridis', label=f'Correlacion {coeficiente_correlacion}')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su nivel de Speechieness\")\n",
    "plt.ylabel(\"Instrumentalness de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Speechieness y Instrumentalness\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "plt.colorbar()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Primero vamos a crear el scatter plot\n",
    "plt.figure(figsize=(6, 6))  # Hacer el gráfico cuadrado\n",
    "\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Energy'], copy_covers_ds['Liveness'])\n",
    "# Graficamos el scatter\n",
    "plt.scatter(copy_covers_ds['Energy'], copy_covers_ds['Liveness'],c=copy_covers_ds[\"Loudness\"], cmap='viridis', label=f'Correlacion {coeficiente_correlacion}')\n",
    "\n",
    "# Agregamos las etiquetas a los ejes\n",
    "plt.xlabel(\"Cantidad de canciones según su nivel de Speechieness\")\n",
    "plt.ylabel(\"Instrumentalness de la canción\")\n",
    "\n",
    "# Agregamos el título\n",
    "plt.title(\"Relación entre Speechieness y Instrumentalness\")\n",
    "\n",
    "# Agregamos una leyenda\n",
    "plt.legend()\n",
    "plt.colorbar()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Sacamos todo lo que no sea continuo y lo que vamos a pintar\n",
    "X = pd.concat([copy_covers_ds['Energy'],copy_covers_ds['Liveness'],copy_covers_ds['Speechiness']],axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#\n",
    "pca = PCA(n_components=2, whiten=False)\n",
    "\n",
    "\n",
    "principalComponents = pca.fit_transform(X)\n",
    "\n",
    "print('Antes de PCA: {}'.format(X.shape))\n",
    "print('Después de PCA: {}'.format(principalComponents.shape))\n",
    "\n",
    "\n",
    "plt.scatter(principalComponents[:,0], principalComponents[:,1],c=copy_covers_ds['Loudness'], cmap='viridis')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Proyección PCA 1')\n",
    "plt.ylabel('Proyección PCA 2')\n",
    "plt.title('Proyección del conjunto de datos a 2 dimensiones')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pca.__dict__"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Key vs mode```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "datos_columna1 = copy_covers_ds['Key']\n",
    "datos_columna2 = copy_covers_ds['Mode']\n",
    "\n",
    "\n",
    "\n",
    "tabla_contingencia = pd.crosstab(datos_columna1, datos_columna2)\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(tabla_contingencia)\n",
    "\n",
    "print(\"Estadistico Chi-Cuadrado: \", chi2)\n",
    "print(\"p-valor: \", p)\n",
    "print(\"Grado de libertad: \", dof)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Time_Signature vs Popularity```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una hipotesis que nos planteamos para analizar mas es: Las canciones que no son de 4 pulsaciones por compás son menos populares.\n",
    "\n",
    "Time Signature es una variable discreta con valores {1,3,4,5} ; Popularity es una variable discreta con valores de minimo: 0 y maximo: 92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que hay muy pocas muestras de 1, 3 y 5 las juntamos en un grupo, aunque aun asi no constrarestan a las de 4."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "time135 = copy_covers_ds[copy_covers_ds['Time_Signature'].isin([1, 3, 5])]\n",
    "time4 = copy_covers_ds[copy_covers_ds['Time_Signature'] == 4]\n",
    "\n",
    "# armamos un boxplot\n",
    "plt.figure(figsize=(6, 6))\n",
    "box = plt.boxplot([time135['Popularity'], time4['Popularity']], tick_labels = [\"1, 3 y 5\", \"4\"], notch=True, patch_artist=True)\n",
    "\n",
    "#Colores para cada boxplot\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.xlabel('Pulsaciones por compas')\n",
    "plt.ylabel('Popularidad')\n",
    "plt.yticks(range(0, 100, 10))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar este boxplot vimos que nuestra hipotesís se fue al piso, ya que las canciones que no son de 4 pulsaciones no son muy poco populares, y las que si son tienen una gran variacion, alli encontramos tanto la canción más popular como la menos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una prueba de Chi-Cuadrado para ver si podemos obtener algo más de información"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "times_popu = copy_covers_ds[['Time_Signature', 'Popularity']].copy()\n",
    "times_popu[ 'TimeS4'] = times_popu['Time_Signature'].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "variable_1 = \"TimeS4\"\n",
    "variable_2 = \"Popularity\"\n",
    "\n",
    "datos_columna1 = times_popu[variable_1]\n",
    "datos_columna2 = times_popu[variable_2]\n",
    "\n",
    "tabla_contingencia = pd.crosstab(datos_columna1, datos_columna2)\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(tabla_contingencia)\n",
    "\n",
    "print(\"Estadistico Chi-Cuadrado: \", chi2)\n",
    "print(\"p-valor: \", p)\n",
    "print(\"Grado de libertad: \", dof)\n",
    "#print(\"Frecuencias esperadas: \\n \", expected)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haciendo una prueba de Chi-Cuadrado, la hipótesis sería: \n",
    "\n",
    "H0 = Son independientes\n",
    "H1 = Son dependientes\n",
    "\n",
    "El p-valor mayor a 0.05, por lo tanto aceptariamos la hipotesis nula, lo que significaria que estadísticamente las variables son independientes. No habria alguna relación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de ```Year vs Popularity```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.boxplot(x='Year', y='Popularity', data=copy_covers_ds, notch=True)\n",
    "plt.title(\"Popularidad por año\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.xticks(ticks=range(len(copy_covers_ds['Year'].unique())), labels=copy_covers_ds['Year'].unique())\n",
    "plt.ylabel(\"Popularity\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Sacamos algunos outliers\n",
    "copy_covers_ds = copy_covers_ds[copy_covers_ds['Popularity'] > 18]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "year_counts = copy_covers_ds['Year'].value_counts().sort_values()\n",
    "\n",
    "# Reordenamos los datos de acuerdo a los años con menos canciones a más canciones\n",
    "ordered_data = copy_covers_ds.copy()\n",
    "ordered_data['Year'] = pd.Categorical(ordered_data['Year'], categories=year_counts.index, ordered=True)\n",
    "\n",
    "\n",
    "sns.boxplot(x='Year', y='Popularity', data=ordered_data, notch=True)\n",
    "plt.title(\"Popularidad por año\")\n",
    "plt.xlabel(\"Año (ordenado por cantidad de canciones)\")\n",
    "plt.ylabel(\"Liveness\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nuestra hipotesis tendria posibilidades de ser cierta tendriamos que ver una tendencia decreciente , siendo los valores de menos canciones(los de la izquierda) mas altos que los valores de popularidad de los años de mas de la derecha(los de mas canciones). No parece ser el caso.\n",
    "\n",
    "Pero bueno, supongamos que agarramos los mas significativos, por ejemplo 1996 y 1991"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_1996_1991 = copy_covers_ds[copy_covers_ds['Year'].isin([1996, 1991])]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_1996_1991['Year'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sns.boxplot(x='Year', y='Popularity', data=copy_1996_1991, notch=True)\n",
    "plt.title(\"Popularidad por año\")\n",
    "plt.xlabel(\"año\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"1996\", \"1991\"])\n",
    "plt.ylabel(\"Popularity\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista no parece que haya una diferencia significativa, pero tendriamos que verlo estadisticamente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "covers_1996 = copy_covers_ds[copy_covers_ds['Year'] == 1996]['Popularity']\n",
    "covers_1991 = copy_covers_ds[copy_covers_ds['Year'] == 1991]['Popularity']\n",
    "\n",
    "\n",
    "stat, p = shapiro(covers_1996)\n",
    "print(f\"Test de Shapiro-Wilk para canciones por encima de la moda: Estadístico={stat:.3f}, p-valor={p:.3f}\")\n",
    "\n",
    "\n",
    "stat, p = shapiro(covers_1991)\n",
    "print(f\"Test de Shapiro-Wilk para canciones por debajo de la moda: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increible, ambas son normales! Homocedasticidad no nos falles porfavor!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import scipy.stats as stats\n",
    "stat, p = stats.levene(covers_1996, covers_1991)\n",
    "print(f\"Test de Levene para Liveness entre ambos grupos de canciones: Estadístico={stat:.3f}, p-valor={p:.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias homocedasticidad sabiamos que podiamos contar contigo! Test t eres el siguiente"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "t_statistic, p_value = stats.ttest_ind(covers_1996, covers_1991)\n",
    "print(f\"Test t para Popularity: Estadístico={t_statistic:.3f}, p-valor={p_value:.3f}\")\n",
    "\n",
    "# Interpretación de los resultados\n",
    "alpha = 0.05  # Nivel de significancia\n",
    "if p_value > alpha:\n",
    "    print(\"No hay suficiente evidencia para rechazar la hipótesis nula.\")\n",
    "    print(\"No hay una diferencia significativa en la popularidad del año 1996 y 1991\")\n",
    "else:\n",
    "    print(\"Se rechaza la hipótesis nula.\")\n",
    "    print(\"Existe una diferencia significativa en la  popularidad del año 1996 y 1991\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como habíamos predicho, no hay una diferencia significativa entre ambos años. Lo que nada indica que la cantidad de canciones por año tenga una influencia en la popularidad de la canciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis y aplicación de regresión para el conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, también podríamos tratar de predecir la popularidad(variable respuesta) de una canción en base a las características de las canciones de forma tal de conocer cualés son las características fundamentales que provocan que una canción sea mas o menos popular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar podríamos hacer una matríz de correlación para apreciar las correlaciones entre las diferente variables, para luego prestar atención a las relaciones entre las distintas características de las canciones y la variable respuesta"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#Primero dropeamos las columnas que no nos sirven(aquellas cualitativas)\n",
    "copy_cuanti_ds = copy_covers_ds.drop(columns=['Track', 'Artist', 'Duration'])\n",
    "\n",
    "# calculamos la matriz de correlación\n",
    "correlation_matrix = copy_cuanti_ds.corr()\n",
    "# la graficamos con un mapa de calor\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, veremos las relaciones que más llaman la atención\n",
    "* Se puede ver que hay una correlación bastante alta entre ```Loudness``` y ```Energy```, cosa que chusmeamos en un análisis anterior\n",
    "* También se aprecia una correlación inversamente grande entre ```Acousticness``` y ```Energy```. Tiene mucho sentido dado que, por lo general, una canción mas enérgica tiende a tener menos elementos acústicos<br>\n",
    "Ahora bien, modelemos las correlaciones con la variable popularity(respuesta) con un gráfico de barras para analizarlo un poquito"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Selecciona solo las correlaciones con Popularity\n",
    "popularity_correlations = correlation_matrix['Popularity'].drop('Popularity')\n",
    "\n",
    "# Ordena las correlaciones de mayor a menor\n",
    "sorted_correlations = popularity_correlations.sort_values(ascending=False)\n",
    "\n",
    "# Crea un gráfico de barras para visualizar las correlaciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "sns.barplot(x=sorted_correlations.values, y=sorted_correlations.index)\n",
    "plt.title('Correlaciones con Popularity')\n",
    "plt.xlabel('Correlación')\n",
    "plt.ylabel('Variable')\n",
    "plt.xlim([-1, 1])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no tenemos ninguna correlación relevante de popularidad con alguna característica de las canciones, no podemos hacer regresión debido que no se cumple el supuesto de correlatividad entre la variable respuesta y las predictoras. Que lastima....\n",
    "Sin embargo.....de la matriz de correlación y de análisis anteriores sabemos que ```Energy``` y ```Loudness``` están bastante correlacionadas(0.65), así que podríamos plantearnos esta nueva hipótesis ¿Se podrá predecir que tan ruidosa es la canción dependiendo de la energía que transmite?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya vimos una correlación relativamente alta entre ```Energy```(nuestra variable independiente) y ```Loudness``` (nuestra variable dependiente). Por lo que tendríamos que usar un scatter plot para ver gráficamente la relación entre las dos:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(copy_covers_ds['Energy'], copy_covers_ds['Loudness'], alpha=0.5)\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Loudness')\n",
    "plt.title('Energy vs Loudness')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El scatter plot muestra una tendencia logarítmica y levemente lineal. Canciones con alta Energy suelen ser más \"intensas\" y, por lo tanto, tienden a ser mezcladas con mayores niveles de Loudness, lo cual es esperado en muchos géneros musicales.  Este patrón sugiere que con una simple regresión lineal se podría capturar bastante bien la relación entre estas dos variables.<br>\n",
    " En este caso vamos a trabajar con el paquete ```statsmodels``` de Python, donde disponemos de la librería sm, que incluye varios modelos estándar de regresión. De ellos vamos a tomar OLS, sigla en inglés de Ordinary Least Squares, o mínimos cuadrados ordinarios.<br>\n",
    " Como vamos a probar con modelo de regresión lineal simple con una sola variable independiente, no es estrictamente necesario hacer algún tipo de estandarización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Separamos nuestra variable independiente\n",
    "X = copy_covers_ds['Energy']\n",
    "# y nuestra variable objetivo (variable dependiente)\n",
    "y = copy_covers_ds['Loudness']\n",
    "\n",
    "# Agregamos una constante como característica, para estimar la ordenada al origen\n",
    "X = sm.add_constant(X)\n",
    "# Ajustamos el modelo\n",
    "model = sm.OLS(y, X).fit()\n",
    "#Imprimimos el resumen de los resultados\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciona, ahora ¿Qué significa cada cosa? Vamos a desglosarlo:\n",
    "* Coeficiente de determinación ```R-squared```:indica qué proporción de la varianza en la variable dependiente (o respuesta) es explicada por el modelo de regresión lineal. En este caso, el valor es del 0.429 lo que muestra que, en este caso, el modelo explica el 42.9% de la varianza total es decir que hay bastante varianza que no explicada, posiblemente de ruido o factores no incluidos en el modelo.\n",
    "*  Significancia del modelo ```F-statistic```: Dice si la varianza explicada por el modelo (gracias a las variables independientes) es significativamente mayor que la varianza residual (o el \"ruido\" que no puede ser explicado por el modelo). Si el valor de F es alto, implica que la varianza explicada es considerablemente mayor que la varianza residual, lo que sugiere que el modelo es significativo. \"Alto\" es algo que por lo general es relativo entre una cosa y otra, así que lo que más nos va a interesar es el p-valor asociado al estadístico. En este caso, el p-valor es recontra bajo (p <<< 0.001), lo que indica que el modelo en su conjunto es significativo. Esto implica que Energy es útil para predecir Loudness con una confianza estadística alta.\n",
    "* El coeficiente de ```Energy``` es 12.4991, lo que significa que por cada unidad que se incrementa la energía de la canción, la ruidosidad aumenta en proporción. Este coeficiente también es muy significativo ( p  <<< 0.001), lo que confirma la fuerte asociación entre ambas variables.<br>\n",
    "* Estadístico ```Omnibus```: Estudia si hay desviaciones significativas en la asimetría y curtosis con respecto a la normalidad. Un  p -valor bajo ( p<0.05 ) sugiere que los residuos no son normales. En este caso nos dió 0, es decir que no se cumple el supuesto de normalidad de los residuos. \n",
    "* El test de ```Jarque-Bera``` también estudia la asimetría y la curtosis, pero usa una metodología diferente. Su  p -valor está marcado como Prob(JB), y también es bajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver estas diferencias en asimetría y curtosis de forma gráfica podemos hacer el histograma de los residuos respecto a la distribución normal:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Histograma de residuos\n",
    "plt.hist(model.resid, bins=20, density=True)\n",
    "# Ajustamos una curva normal a esos residuos\n",
    "mu, std = norm.fit(model.resid)\n",
    "# Graficamos la curva de la distribución normal\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Residuales\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.title(\"Histograma de los residuos\")\n",
    "plt.legend([\"Distribución normal\", \"Residuos\"])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve que aunque hay una silueta \"acampanada\", tenemos un desplazamiento leve hacia valores positivos, y una cola (la de la izquierda)<br>\n",
    "Otra forma de estudiar la validez del modelo es representando gráficamente los valores ajustados por el modelo vs. los residuos. Deberíamos observar un comportamiento \"en banda\" alrededor del 0, sin demasiados errores por encima o debajo del 3 y el -3, respectivamente (porque en una normal estándar los valores por fuera del intervalo [-3, 3] son muy poco frecuentes). Si observamos un patrón diferente a eso, entonces estamos vulnerando alguno de los supuestos:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.scatter(model.fittedvalues, model.resid)\n",
    "plt.xlabel(\"Valores ajustados\")\n",
    "plt.ylabel(\"Residuos\")\n",
    "plt.title(\"Valores adjustados vs. residuos\")\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.yticks(range(-30, 10, 3))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y acá vemos claramente que no se cumple con lo esperado, si bien tiene un forma aparentemente en banda, hay bastantes errores por fuera del [-3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra hipótesis caída :(, ¿Qué hacemos entonces?¿Se podrá predecir mejor Loudness si incorporamos más variables? Es posible. El tema está en cuáles son esas variables ideales para predecir la cantidad de decibelios que tendrá una canción. Indagando un poco por internet encontramos que otras posibles variables que influyen en ```Loudness``` pueden ser:\n",
    "* ```Tempo```: Canciones con tempos más altos a menudo requieren más instrumentos percusivos y arreglos dinámicos, lo que puede contribuir a un mayor volumen percibido.\n",
    "* ```Danceability```: Canciones con alta danceability suelen ser más rítmicas y podrían tener mayores niveles de loudness debido a beats marcados y repetitivos\n",
    "* ```Instrumentalness```: Las canciones instrumentales, especialmente aquellas de géneros como música clásica o ambiental, tienden a tener niveles de loudness más bajos. Por el contrario, canciones con muchas voces y producción vocal suelen ser más ruidosas\n",
    "*  ```Key y Mode```: Las canciones en modo mayor y tonalidades específicas (por ejemplo, tonalidades brillantes como C, D o G) pueden percibirse más \"fuertes\" debido a su resonancia.\n",
    "*  ```Valence```: Canciones más alegres tienden a tener una producción más brillante y fuerte, mientras que las canciones tristes suelen ser más silenciosas y sutiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a ver como son las correlaciones de ```Loudness``` con esas variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Selecciona solo las correlaciones con Loudness\n",
    "loudness_correlations = correlation_matrix['Loudness'].drop('Loudness')\n",
    "\n",
    "# Ordena las correlaciones de mayor a menor\n",
    "sorted_correlations = loudness_correlations.sort_values(ascending=False)\n",
    "\n",
    "# Crea un gráfico de barras para visualizar las correlaciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid(True)\n",
    "sns.barplot(x=sorted_correlations.values, y=sorted_correlations.index)\n",
    "plt.title('Correlaciones con Loudness')\n",
    "plt.xlabel('Correlación')\n",
    "plt.ylabel('Variable')\n",
    "plt.xlim([-1, 1])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las más correlacionadas son ```Energy```, ```Valence```, ```Danceability```, ```Acousticness``` e ```Instrumentalness```. Vamos a hacer los scatter-plot para ver si vemos una relación aproximadamente lineal"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import  numpy as np\n",
    "#Instrumentalness vs Loudness\n",
    "plt.figure(figsize=(8, 6))\n",
    "#Calculamos el coeficiente de correlación con numpy\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Loudness'], copy_covers_ds['Instrumentalness'])[0, 1]\n",
    "\n",
    "plt.scatter(copy_covers_ds['Loudness'], copy_covers_ds['Instrumentalness'], label=f'Correlacion {coeficiente_correlacion}', alpha=0.5)\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Instrumentalness')\n",
    "plt.title('Instrumentalness vs Loudness')\n",
    "plt.legend([f\"Correlación: {coeficiente_correlacion:.4f}\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "#Acousticness vs Loudness\n",
    "plt.figure(figsize=(8, 6))\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Loudness'], copy_covers_ds['Acousticness'])[0, 1]\n",
    "plt.scatter(copy_covers_ds['Loudness'], copy_covers_ds['Acousticness'], label=f'Correlacion {coeficiente_correlacion}', alpha=0.5)\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Acousticness')\n",
    "plt.title('Acousticness vs Loudness')\n",
    "plt.legend([f\"Correlación: {coeficiente_correlacion:.4f}\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "#Valence vs Loudness\n",
    "plt.figure(figsize=(8, 6))\n",
    "coeficiente_correlacion = np.corrcoef(copy_covers_ds['Loudness'], copy_covers_ds['Valence'])[0, 1]\n",
    "plt.scatter(copy_covers_ds['Loudness'], copy_covers_ds['Valence'], label=f'Correlacion {coeficiente_correlacion}', alpha=0.5)\n",
    "plt.xlabel('Loudness')\n",
    "plt.ylabel('Valence')\n",
    "plt.title('Valence vs Loudness')\n",
    "plt.legend([f\"Correlación: {coeficiente_correlacion:.4f}\"], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, ninguna cumple con que el supuesto de correlación lineal. Por lo tanto, no podemos hacer regresión lineal múltiple. Quizá se pueda hacer algún otro tipo de análisis con regresión no lineal, pero como no fue un tema tratado en la materia, lo dejaremos acá por ahora😢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de grupos con clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar técnicas de clustering para identificar comportamiento común que nos permita agrupar canciones con características similares, lo que es útil para identificar géneros o subgrupos de música dentro de esta década icónica.\n",
    "Sería útil seleccionar variables que determinen subgéneros musicales, como ```Danceability```, ```Energy```, ```Tempo```, ```Acousticness```, ```Instrumentalness``` y ```Valence```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para identificar estos grupos podemos usar el algoritmo K-means. El mismo se basa en descubrir K centroides en los datos que me representen los diferentes agrupamientos que puedan llegar a existir, de manera iterativa y basándose en la distancia entre las muestras.\n",
    "En Sklearn, el algoritmo de K-means se llama KMeans y viene dentro del paquete cluster. El hiperparámetro más importante es n_clusters, que no es más que el valor de K. Vamos a generar una primera partición en 4 clusters y ver los resultados que obtenemos.\n",
    "Primero, normalizamos los datos dejar bien armado los campos del dataset. En este caso lo haremos utilizando normalización por rangos, según el valor mínimo/máximo de cada columna. Para eso vamos a usar la clase MinMaxScaler de Sklearn debido a su simpleza."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Seleccionamos las columnas numéricas para la normalización\n",
    "numeric_cols = copy_covers_ds.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Creamos un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Ajustamos el scaler a los datos y transformamos los datos\n",
    "copy_covers_ds[numeric_cols] = scaler.fit_transform(copy_covers_ds[numeric_cols])\n",
    "\n",
    "# Imprimimos el DataFrame con los datos normalizados\n",
    "copy_covers_ds.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si usamos K-means para encontrar los grupos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# separamos las features de los nombres de los países\n",
    "songs = copy_covers_ds['Track']\n",
    "features_songs = copy_covers_ds.drop(columns=['Track', 'Artist', 'Duration'])\n",
    "\n",
    "# inicializamos un objeto de la clase KMeans con el modelo\n",
    "kmeans = KMeans(n_clusters=4, verbose=0, random_state=10)\n",
    "# lo aplicamos sobre nuestros datos para hallar los centroides\n",
    "kmeans.fit(features_songs)\n",
    "# y obtenemos los clusters a los que fueron asignadas las muestras\n",
    "clusters_kmeans = kmeans.predict(features_songs)\n",
    "\n",
    "# Creamos un DataFrame con los países y los clusters asignados\n",
    "cluster_df = pd.DataFrame({'Track': songs, 'Cluster': clusters_kmeans})\n",
    "\n",
    "# Imprimimos los países de cada cluster\n",
    "for cluster_num in range(4):\n",
    "  print(f\"\\nCluster {cluster_num}:\")\n",
    "  print(cluster_df[cluster_df['Cluster'] == cluster_num]['Track'].tolist())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien separa correctamente las canciones en los distintos clusters. Podemos representar el resultado en un scatter plot para apreciarlo mejor. Como tenemos una dimensionalidad alta, necesitaremos usar t-sne o PCA para trasladar los resultados a dos dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Reducir la dimensionalidad de los datos usando t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(features_songs)\n",
    "\n",
    "# Crear un DataFrame con los resultados de t-SNE y los clusters\n",
    "tsne_df = pd.DataFrame({'x': tsne_results[:, 0], 'y': tsne_results[:, 1], 'Cluster': clusters_kmeans, 'Track': songs})\n",
    "\n",
    "# Graficar los resultados de t-SNE, coloreando los puntos según el cluster\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster_num in range(4):\n",
    "  plt.scatter(tsne_df[tsne_df['Cluster'] == cluster_num]['x'], tsne_df[tsne_df['Cluster'] == cluster_num]['y'], label=f'Cluster {cluster_num}')\n",
    "\n",
    "  # Seleccionamos 5 canciones para etiquetar en cada cluster\n",
    "  songs_to_label = tsne_df[tsne_df['Cluster'] == cluster_num]['Track'].tolist()\n",
    "  songs_to_label = songs_to_label[:5]\n",
    "\n",
    "  for song in songs_to_label:\n",
    "    row = tsne_df[(tsne_df['Cluster'] == cluster_num) & (tsne_df['Track'] == song)]\n",
    "    if not row.empty:\n",
    "      plt.text(row['x'].values[0], row['y'].values[0], song, fontsize=8)\n",
    "\n",
    "plt.xlabel('Componente t-SNE 1')\n",
    "plt.ylabel('Componente t-SNE 2')\n",
    "plt.title('Resultados del clustering con K-means (t-SNE)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De una observamos que el cluster 2 está muy separado de los demás. Podemos indagar un poco sobre el por qué de está diferencia. Por ejemplo, podemos tomar algunas canciones del cluster 2 y compararlas con las de otros clusters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seleccionamos aleatoriamente 5 canciones del Cluster 2, y 5 de los otros clusters para la comparación\n",
    "cluster_2_songs = tsne_df[tsne_df['Cluster'] == 2].sample(5, random_state=42)\n",
    "other_clusters_songs = tsne_df[tsne_df['Cluster'] != 2].groupby('Cluster').apply(lambda x: x.sample(5, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Combinamos las canciones seleccionadas en un solo DataFrame\n",
    "comparison_songs = pd.concat([cluster_2_songs, other_clusters_songs])\n",
    "\n",
    "# Extraemos las características de las canciones seleccionadas\n",
    "features_comparison = features_songs.loc[comparison_songs.index]\n",
    "\n",
    "# Agregamos la columna de clusters y nombres de las canciones para identificación\n",
    "features_comparison = features_comparison.assign(Cluster=comparison_songs['Cluster'].values, Track=comparison_songs['Track'].values)\n",
    "\n",
    "# Seleccionamos solo las columnas numéricas para calcular la media\n",
    "numeric_features_comparison = features_comparison.select_dtypes(include=[np.number])\n",
    "\n",
    "# Agregamos de nuevo la columna Cluster para hacer la agrupación\n",
    "numeric_features_comparison['Cluster'] = features_comparison['Cluster'].values\n",
    "\n",
    "# Comparamos las características de cada canción, calculando la media de cada atributo por cluster\n",
    "mean_features_by_cluster = numeric_features_comparison.groupby('Cluster').mean()\n",
    "\n",
    "print(\"Promedio de las características por Cluster:\")\n",
    "print(mean_features_by_cluster)\n",
    "\n",
    "# Visualizamos las diferencias en los atributos entre los clusters\n",
    "# Seleccionamos algunos atributos para graficar\n",
    "attributes_to_compare = ['Danceability', 'Energy', 'Loudness', 'Valence', 'Tempo', 'Popularity', 'Instrumentalness', 'Acousticness', 'Speechiness']\n",
    "\n",
    "# Crear gráfico de barras para cada atributo\n",
    "fig, axes = plt.subplots(nrows=len(attributes_to_compare), ncols=1, figsize=(10, 40))\n",
    "\n",
    "for i, attribute in enumerate(attributes_to_compare):\n",
    "    mean_features_by_cluster[attribute].plot(kind='bar', ax=axes[i], color=['blue', 'orange', 'green', 'red'])\n",
    "    axes[i].set_title(f'Comparación del atributo {attribute} por cluster')\n",
    "    axes[i].set_ylabel(attribute)\n",
    "    axes[i].set_xlabel(\"Cluster\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genial! Ahora a sentarnos a ver las diferencias más grandes entre los clusters:\n",
    "* ```CLuster 0```: Poca lírica, muy instrumentales, muy populares, tempo medio-alto, baja positividad, muy enérgicas y bailables. Con esta descripción, podrían ser canciones de, por ejemplo, metal o electrónica\n",
    "* ```Cluster 1```: Cantidad normal de lírica, con mucha instrumentación acústica, bastante populares, tempo medio-bajo, energía media y muy bailables. Podrían ser canciones estilo balada, románticas\n",
    "*  ```Cluster 2```: Muy habladas, pocos elementos acústicos, nivel de popularidad media, tempo muy rápido, transmiten mucha positividad, bastantes ruidosas, enérgicas y bailables. Parecen ser canciones estilo rap, hip-hop\n",
    "* ```Cluster 3```: Casi nada de lírica, muy acústicas, populares, tempo-medio, bastante alegres y ruidosas, enérgicas y no muy bailables, por ejemplo folk, jazz o blues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien, que hubiese pasado si elegíamos cantidad de clusters n = 3, o igual a 2, o igual a 5, etc. Para evitar tener que elegir la cantidad,podemos aplicar un algoritmo de Clustering jerárquico<br>\n",
    "Tomarémos un enfoque aglomerativo(se toman diferentes pares de muestras y se unen según qué tan cerca se encuentren entre sí, hasta unirlas a todas en un único clúster), construyendo un dendograma de forma iterativa en donde se unen las muestras entre sí según se vayan poniendo en un mismo cluster, y donde se representan las uniones con una altura equivalente a la distancia euclidea entre los elementos que se unen."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# generamos el clustering jerárquico\n",
    "linked = linkage(copy_cuanti_ds, method='single')\n",
    "\n",
    "# ploteamos el dendrograma\n",
    "plt.figure(figsize=(30,7))\n",
    "dendrogram(linked,\n",
    "           orientation='top',\n",
    "           labels=list(songs), # oko que hay que pasarle una lista\n",
    "           distance_sort='descending',\n",
    "           show_leaf_counts=True,\n",
    "           leaf_font_size=10,\n",
    "           truncate_mode='lastp', p=100) #Lo truncamos para visualizar los clusters más relevantes\n",
    "plt.xlabel('Canciones')\n",
    "plt.ylabel('Distancia euclídea')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las canciones que se encuentran cerca en el eje x son más similares entre sí. Si dos canciones están unidas a una altura baja, significa que tienen características muy parecidas. Por ejemplo, en el dendograma, se pueden apreciar canciones como \"Runaway\", \"November Rain\" y \"Feels So Good\" en un cluster separado del resto, esto indica que son muy distintas del resto de canciones. Le vamos a echar un ojo a ver si sabemos el porqué de esta diferencia"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds[copy_covers_ds['Track'] == 'Feels So Good']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds[copy_covers_ds['Track'] == 'November Rain']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "copy_covers_ds[copy_covers_ds['Track'] == 'Runaway']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer, este cluster está lleno de canciones con mucha duración, se puede apreciar que las tres tiene valores cercanos a los 10min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener los clusters de una solución particular, debemos aplicar el algoritmo aglomerativo una vez más. Para hacerlo de otra forma, vamos a hacerlo ahora usando ```Sklearn```. Si lo particionaramos en 40, obtendríamos 3 clusters:lo pintado de verde, lo de azul y lo de naranja"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# creamos el objeto para el clustering aglomerativo, eliminamos affinity porque no es necesario con linkage='single'\n",
    "agglomerative = AgglomerativeClustering(n_clusters=3, linkage='single')\n",
    "# usamos fit predict para buscar los clusters y devolverlos\n",
    "clusters_agglomerative = agglomerative.fit_predict(copy_cuanti_ds)\n",
    "\n",
    "# imprimimos por pantalla los nombres de los países asignados a cada cluster\n",
    "for k in np.unique(clusters_agglomerative):\n",
    "  print('Cluster {}'.format(k))\n",
    "  print(songs[clusters_agglomerative==k])\n",
    "  print('======')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Ahora vamos a evaluar las que tan acertadas son estas soluciones de clustering que encontramos mediante el Índice de Davies Bouldin y el Coeficiente de silueta. Para ello usaremos la libreria ```SKLearn```."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import davies_bouldin_score, silhouette_score\n",
    "\n",
    "# inicializamos listas con los resultados de cada algoritmo y los nombres de los\n",
    "# algoritmos\n",
    "clusters_to_compare = [clusters_kmeans, clusters_agglomerative]\n",
    "clustering_methods = ['K-means', 'Hierarchical Clustering']\n",
    "\n",
    "# inicializamos vectores donde iremos guardando los resultados\n",
    "db_scores = np.zeros(len(clusters_to_compare))\n",
    "silhouette_scores = np.zeros(len(clusters_to_compare))\n",
    "\n",
    "# por cada uno de los métodos\n",
    "for i in range(len(clusters_to_compare)):\n",
    "  # calculamos las métricas\n",
    "  db_scores[i] = davies_bouldin_score(copy_cuanti_ds, clusters_to_compare[i])\n",
    "  silhouette_scores[i] = silhouette_score(copy_cuanti_ds, clusters_to_compare[i])\n",
    "  # las imprimimos\n",
    "  print(clustering_methods[i])\n",
    "  print('DB score: {:.4f}'.format(db_scores[i]))\n",
    "  print('Silhouette score: {:.4f}'.format(silhouette_scores[i]))\n",
    "  print('----------')\n",
    "\n",
    "# inicializamos un gráfico para cada métrica\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "# graficamos el Davies Bouldin score\n",
    "axes[0].bar(np.arange(db_scores.size), db_scores)\n",
    "axes[0].set_title('Davies Boulding Score')\n",
    "axes[0].set_xlabel('Clustering method')\n",
    "axes[0].set_ylabel('Davies Boulding Score')\n",
    "axes[0].set_xticks(np.arange(db_scores.size))\n",
    "axes[0].set_xticklabels(clustering_methods, rotation=45)\n",
    "axes[0].grid(True)\n",
    "# y el Silhouette Score\n",
    "axes[1].bar(np.arange(silhouette_scores.size), silhouette_scores)\n",
    "axes[1].set_title('Silhouette Score')\n",
    "axes[1].set_xlabel('Clustering method')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_xticks(np.arange(silhouette_scores.size))\n",
    "axes[1].set_xticklabels(clustering_methods, rotation=45)\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso logramos que el método de clustering jerárquico supere significativamente al de K-means tanto en términos del Davies Boulding score como del Silhouette Score. Esto implica que los clusters que encontramos con este método están mejor separados entre sí y tienen más densidad interna. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
